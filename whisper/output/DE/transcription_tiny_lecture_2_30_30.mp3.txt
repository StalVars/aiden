  Wir können auch Eigenschaften definieren, die die Effekte der von Agentinnen ausgeführten Aktionen in einer Umgebung charakterisieren. Wenn die Effekte von Aktionen wie geplant eintreten, dann nennen wir die Umgebung deterministisch, sonst stochastisch. Ein Beispiel dazu, wenn eine Agentin sich entscheidet, eine Figur in einem Schachspiel zu bewegen, können wir erwarten, dass sich diese Figur zur neuen Position bewegt. Ein Schachspiel kann als eine Umgebung mit deterministischen Aktionen modelliert werden. Wenn die Agentin einen Würfel wirft, kann sie nicht vorhersehen, welche Nummer der Würfel zeigt, sobald er zum stehen kommt. Ein Würfel zu werfen ist eine stochastische Aktion. Das mögliche Ergebnis dieser Aktion kann nur mit Hilfe von Wahrscheinlichkeiten modelliert werden. Die Aktion eines Münzwurfs ist somit stochastisch mit zwei möglichen Ergebnissen. Wenn die Münze nicht gefälscht ist, können wir nicht wissen, auf welcher Seite sie landet, jedes Ergebnis hat eine Wahrscheinlichkeit von ein Halb. Ein weiteres Beispiel sind Straßenumgebungen. Bremsen auf einer trockenen Straße ist deterministisch. Das Auto wird nach einer von seiner Geschwindigkeit abhängigen Strecke zum stehen kommen. Auf vereistend Straßen zu Bremsen ist stochastisch, die Agentin kann nicht sicher wissen, wo das Auto zum stehen kommen wird. Mit der zweiten Aktionseigenschaft untersuchen wir, ob die Effekte von Aktionen nur vom aktuellen Zustand oder vom Verlauf der bisher ausgeführten Aktionen abhängig sind. Wir unterscheiden zwischen episodischen und sequenziellen Aktionen. Im Falle einer episodischen Aktion brauchen wir kein Wissen über die Vergangenheit, um gute Entscheidungen zu treffen. Episodisches Gedächtnis ist ein anderer Ausdruck für das Kurzzeitgedächtnis. Ein E-Agentin hat die Informationen über den aktuellen Zustand und die Auswirkungen möglicher Aktionen im Kurzzeitgedächtnis gespeichert. Wenn eine episodische Aktion ausgewählt wird, kann sie genau den Folgezustand nach Ausführung der Aktion feststellen, ohne dabei die Ergebnisse früherer Aktionen berücksichtigen zu müssen. Sequenzielle Umgebungen benötigen ein Langzeitgedächtnis, um gute Entscheidungen über die als nächstes auszuführende Aktion zu treffen, denn Aktionen können Langzeiteffekte haben. Damit Agentinnen erfolgreich in sequenziellen Dominnen handeln können, müssen sie sich an die Vergangenheit erinnern, um in der Zukunft gute Entscheidungen treffen zu können. Ein Beispiel für eine sequenzielle Umgebung ist das Schachspiel. Die Effekte eines nächsten Zugeshängen von früheren Zügen ab, wenn die Agentinnen abschätzen will, ob ein Zug die Gewinnchancen erhöht und zum Beispiel dazu führt, dass der König bedroht wird. Andererseits, wenn wir nur die Aktion des Bewegehens einer einzelnen Schachfigur beachten, ist die Umgebung episodisch, die Figur wird zum neuen Feld auf dem Brett bewegt unabhängig von vorherigen Spielzügen. Ein weiteres Beispiel für eine episodische Umgebung sind bildverarbeitende Systeme, die Objekte klassifizieren. Beispiele sequenzieller Umgebungen sind selbstfahrende Autos oder Investitionen in Aktien. Zu guter Letzt sind wir daran interessiert zu verstehen, ob mehrere Agentinnen in einer Umgebung agieren. Wenn Agentinnen eine Aktion ausführen, ohne dabei berücksichtigen zu müssen, welche Aktionen andere Agenten ausführen, sprechen wir von einer Einzelagenten Umgebung. Wenn andere Agentinnen in der Umgebung handeln und ein Agent die Handlungen dieser anderen Agenten berücksichtigen muss, sprechen wir von einer Multiagenten Umgebung. Schach ist eine Multiagenten Umgebung mit zwei Agent-Stärnchen innen. Bei der Entscheidung für den nächsten Spielzug muss die Agent in die früheren Züge des Gegners beachten.
