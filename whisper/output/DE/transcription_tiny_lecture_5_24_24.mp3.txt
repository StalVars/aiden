  Der grundlegende MCT-Prozess baut den Suchbaum auf incrementelle und asymetrische Weise auf. In jeder Interation verwendet der Algorithmus die sogenannte Baumpolitik, um den nächsten zu erweiternen Knoten zu bestimmen. Der Algorithmus wählt diesen Knoten aus, hier in Blaudar gestellt, und führt von diesen Knoten aus eine Simulation durch, in dem erzufällig Aktionen ausführt. Eine solche Simulation wird auch als zufälliger Rollout bezeichnet. Diese Simulation führt zu einem Entzustand, der ein Zielzustand, eine Sackgasse oder ein beliebiger anderer Zustand sein kann. Zum Beispiel ein Zustand in einer vor definierten Tiefe, in der keine weiteren Aktionen ausgeführt werden können. Dieser Zustand wird ausgewertet und ergibt die Belohnung, die man mit der Sequenz der zufälligen Aktionen erhält. Die Belohnung wird den Baum hinauf propagiert und beeinflusst, wie der Algorithmus die Suche fortsetzt, basierend auf der vom Algorithmus verwendeten Baumpolitik. Es besteht ein Gleichgewicht zwischen Erkundung und Ausnutzung. Der Algorithmus erkundet weiterhin unbekannte Bereiche des Suchraums, sucht aber auch intensiver in Bereichen, die gute Belohnungen liefern.
