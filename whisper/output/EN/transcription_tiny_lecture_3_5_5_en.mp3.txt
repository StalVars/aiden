  In the last lecture, we introduced intelligent agents. Let us briefly recall important aspects of a goal-based agent. Through sensors, this agent can perceive the world being in different states and derive a state description. The initial state is the current state of the world. A goal, or several goals, are states that the agent wants the world to be in the future. These states are desirable for the agent. The agent has background knowledge about how the world can evolve. What actions the agent has at its disposal to change the state of the world, and the agent can reason about how its actions change the state of the world. This means that if the agent sets some goals, it can check which actions it should select and execute in the current and possibly subsequent states of the world to achieve a state of the world where the goals are true.
