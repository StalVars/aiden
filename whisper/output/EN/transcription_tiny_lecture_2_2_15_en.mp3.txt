  In this lecture, we will look more closely at the model of the rational agent on which we briefly touched in the introduction lecture. We'll go deeper into the interplay of perception, cognition and action. We discuss how agents can act in different environments and discuss properties that can be used to characterize environments. We also introduce several types of agents in their underlying architectures. We discuss the simple reflex agent, the model-based reflex agent, the goal-based agent, the utility-based agent, and the learning agent. The recommended reading is chapter 2 of our textbook. It covers all the material that I discuss in this lecture. The metaphor of the rational agent has been very important for the last 40 years of artificial intelligence research. A central aspect of intelligence is the ability to act successfully in the world. We are therefore interested in AI systems, which are successfully acting agents. In this course, we will answer questions such as, how can agents perceive the environment in which they act? What does it need for an agent to act successfully in an environment? What does it mean to be able to execute actions? What does it need for an agent to be successful in different environments? So what is an agent? This video shows two agents as we know them from action movies. They are not only agents in the sense of a secret service. Angelina Jolie, acting as Mrs. Smith, does the three steps, which we require from any agent, she perceives Brad Pitt's car. Based on what she perceives, she anticipates the consequences of him driving in the explosion circle. She thus takes a decision to disarm the system. This decision leads to an action. She gets up and disconnects the cables from the control device. Thereby, she takes action to stop the explosion to happen. Summarizing, we can formulate the following properties of an intelligent agent. An agent must be able to perceive the environment. The perceptions must be used to take decisions, and the decisions will result in actions. If the agent is rational, its decisions must be rational. Being rational means that the decisions must lead to the best possible action the agent can take in the current situation. Having defined these four properties of the rational agent and we can now use them to build a iSystems that can act successfully in the world. As a side remark on the slide, you also see a yellow star. Starting with this lecture, I begin marking especially relevant slides with these stars. Was the decision taken by Mrs. Smith a rational decision? Is Mrs. Smith acting here as a rational agent? Yes. By stopping the explosion, she saves the life of a person she considers to be not involved in her current investigation. Based on what she currently knows, she considers the man to be an innocent, idiot, as she says. She also saves the explosion equipment for further use to reach her original goal, which was to attack the approaching convoy of cars. Let us watch this short video sequence again to recapulate the behavior of the rational agent consisting of perception, decision, action. The name, agent, originally comes from the Greek word of agare, something that acts. A rational agent acts to achieve the best expected outcome. Rational thinking is a possible mechanism to achieve rational behavior. Perfect rationality cannot be achieved in complex environments, because we cannot anticipate all information that should influence our decision making and acting. Therefore, we consider a form of limited rationality. We consider an agent as being rational when the agent acts appropriately in a given situation having its limited resources available. Being rational does not mean that the agent knows everything about the world and the consequences of its behavior or the behavior of other agents. A rational agent is not an omniscient agent. Omniscient agents know the actual effects of all their actions and can perfectly foresee the future. This is of course not a realistic capability that would be within reach and something that we can build, as the future will always remain uncertain, and the world cannot be fully controlled. Therefore, a rational agent can only maximize the expected useful results or positive outcomes of its behavior. The rational agent behaves according to its perceptions from the environment. It may also have some background knowledge learned and acquired over time. Based on the percepts and possible prior knowledge, it tries to be in situations it personally finds useful for itself. For example, if I am hit by a meteorite while crossing the street, I can hardly be accused of lacking rationality. It's rather unusual that I'm hit by a meteorite and looking above into the sky is a rather uncommon behavior when crossing a street. But on the other hand, if I cross the street without looking left or right and get hit by a car, my behavior can hardly be considered as being rational as I know that cars drive on streets and may not be able to break immediately to avoid an accident. It certainly does not maximize my chance to safely cross the street when I do not look before I start crossing. Rationality maximizes expected performance. In contrast, perfection maximizes actual performance. Here you can see the basic architecture of an agent. Any agent needs to have these elements shown in this architecture to be able to satisfy the three properties we define. The agent is equipped with sensors and actuators, and a white box element marked with a question mark in the middle. The agent uses the sensors to receive percepts from the environment. The internal white box element represents its capability to take a decision based on the percepts and then to select an action. With the help of its actuators, the agents can execute the action in the environment. When building intelligent agents in AI application systems, we need to decide with which sensors and actuators the agent will be equipped. What sensors does it need to receive important properties from the environment in its percepts and what actuators does it need to execute certain actions? Furthermore, we need to decide what is put into the white box element. What capabilities do we need to implement for the agent to reason and decide? Our decisions are based on our understanding of the environment and its complexity. We also need to define the boundary between agent and environment and the influence of agent and environment on each other. On this slide you can see a simplified model of a human agent. Humans have sensors such as for example their eyes and their ears. Or take the skin, through which we can also obtain information from and about the environment. We have our brain to reason about our percepts. The brain fills in the white box element marked with the question mark. We also have actuators such as our hands, our voice, and our legs for example. With these actuators we execute actions in the environment. Executing actions leads to changes in the environment, which in turn lead to new percepts that we can perceive through our sensors. Although we are agents too, we are not always rational agents. It is good that we are not always rational because this would otherwise lead us to maximize our own selfish interests only. Humans are often irrational, but also for the good of other humans.
